{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use %matplotlib inline in the first cell of the notebook\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load data from the IMDB dataset\n",
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data (Have to turn lists into tensors.)\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the network\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the network\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 4s 233us/step - loss: 0.5087 - acc: 0.7807 - val_loss: 0.3794 - val_acc: 0.8695\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.3006 - acc: 0.9055 - val_loss: 0.3003 - val_acc: 0.8900\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.2180 - acc: 0.9283 - val_loss: 0.3081 - val_acc: 0.8715\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s 95us/step - loss: 0.1750 - acc: 0.9436 - val_loss: 0.2838 - val_acc: 0.8839\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 1s 79us/step - loss: 0.1425 - acc: 0.9545 - val_loss: 0.2848 - val_acc: 0.8863\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 1s 83us/step - loss: 0.1148 - acc: 0.9654 - val_loss: 0.3146 - val_acc: 0.8776\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 1s 88us/step - loss: 0.0978 - acc: 0.9706 - val_loss: 0.3130 - val_acc: 0.8846\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0806 - acc: 0.9765 - val_loss: 0.3860 - val_acc: 0.8649\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 1s 78us/step - loss: 0.0660 - acc: 0.9821 - val_loss: 0.3636 - val_acc: 0.8778\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 1s 78us/step - loss: 0.0556 - acc: 0.9851 - val_loss: 0.3845 - val_acc: 0.8792\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 1s 84us/step - loss: 0.0446 - acc: 0.9889 - val_loss: 0.4163 - val_acc: 0.8769\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 1s 80us/step - loss: 0.0383 - acc: 0.9915 - val_loss: 0.4510 - val_acc: 0.8698\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0297 - acc: 0.9929 - val_loss: 0.4703 - val_acc: 0.8733\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0244 - acc: 0.9949 - val_loss: 0.5034 - val_acc: 0.8726\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 1s 80us/step - loss: 0.0173 - acc: 0.9981 - val_loss: 0.5448 - val_acc: 0.8691\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 1s 78us/step - loss: 0.0167 - acc: 0.9968 - val_loss: 0.5746 - val_acc: 0.8705\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 1s 76us/step - loss: 0.0092 - acc: 0.9995 - val_loss: 0.6230 - val_acc: 0.8649\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 1s 76us/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.6419 - val_acc: 0.8663\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0105 - acc: 0.9978 - val_loss: 0.6772 - val_acc: 0.8660\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 1s 83us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 0.6947 - val_acc: 0.8650\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 106us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.76433708021879199, 0.85043999999999997]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the call to model.fit() returns a History object. This object has a member history, \n",
    "# which is a dictionary containing data about everything that happened during training. \n",
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIJSgoiIpKgpCAiIglKCiIikvD/ASX6Br0FIJDwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5566dea320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train a new network from scratch for four epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 1s 55us/step - loss: 0.4728 - acc: 0.8216\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 1s 56us/step - loss: 0.2666 - acc: 0.9097\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 1s 52us/step - loss: 0.2031 - acc: 0.9286: 0s - loss: 0.2083 - acc\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 1s 47us/step - loss: 0.1714 - acc: 0.9386\n",
      "25000/25000 [==============================] - 2s 86us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31151636449813841, 0.87644]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "We get higher accuracy (87.6% vs 85.0%) when we do early stopping (hard-coded stop at 4 epochs) to avoid overfitting.\n",
    "Not bad for a naive approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary the number of layers\n",
    "Try using 1 or 3 hidden layers. How does it affect validation and test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 1s 55us/step - loss: 0.4484 - acc: 0.8281\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 1s 51us/step - loss: 0.2763 - acc: 0.9077\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 1s 50us/step - loss: 0.2188 - acc: 0.9254: 0s - loss: 0.2153\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 1s 42us/step - loss: 0.1857 - acc: 0.9361\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 1s 42us/step - loss: 0.1636 - acc: 0.9441\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 1s 45us/step - loss: 0.1473 - acc: 0.9498\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 1s 47us/step - loss: 0.1336 - acc: 0.9557\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 1s 44us/step - loss: 0.1227 - acc: 0.9602\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 1s 46us/step - loss: 0.1124 - acc: 0.9642\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 1s 47us/step - loss: 0.1033 - acc: 0.9670\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 1s 51us/step - loss: 0.0960 - acc: 0.9698\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 1s 50us/step - loss: 0.0892 - acc: 0.9726\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 1s 52us/step - loss: 0.0821 - acc: 0.9747\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.0777 - acc: 0.9762\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 1s 51us/step - loss: 0.0712 - acc: 0.9794\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 1s 47us/step - loss: 0.0668 - acc: 0.9800\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 1s 49us/step - loss: 0.0611 - acc: 0.9837\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 1s 47us/step - loss: 0.0577 - acc: 0.9841\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 1s 45us/step - loss: 0.0533 - acc: 0.9860\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 1s 44us/step - loss: 0.0495 - acc: 0.9866\n",
      "25000/25000 [==============================] - 2s 78us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.54126441997766495, 0.85240000000000005]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define validation data\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2137ca743f28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 61us/step - loss: 0.4644 - acc: 0.8123\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 1s 51us/step - loss: 0.2526 - acc: 0.9082\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.1961 - acc: 0.9284\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.1653 - acc: 0.9403\n",
      "25000/25000 [==============================] - 3s 103us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30084662718772887, 0.88388]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "How does 1 or 3 layers affect validation and accuracy?\n",
    "Compared to baseline:\n",
    "\n",
    "    1 layer:  increase accuracy (best)\n",
    "    3 layers: increase accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
